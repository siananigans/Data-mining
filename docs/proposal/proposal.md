# School of Computing &mdash; Year 4 Project Proposal Form


## SECTION A

|                     |                   |
|---------------------|-------------------|
|Project Title:       | Anomaly detection using different data-mining techniques            |
|Student 1 Name:      | Shannon Mulgrew   |
|Student 1 ID:        | 16304263            |
|Student 2 Name:      | Sian   Lennon         |
|Student 2 ID:        | 16343896            |
|Project Supervisor:  | Mark Roantree            |



## SECTION B


### Introduction

Our proposed project is a data-mining based research project specifically focusing on anomaly/outlier detection. The project will investigate the usefulness of different anomaly detection techniques for a number of different datasets.

### Outline

The main goal of the project is to create and apply a number of anomaly detection algorithms using various techniques on different data-sets. The purpose of this is to find the best suited algorithm for anomaly detection for each particular data-set. We want to research which technique/algorithm is best suited for a particular data set based on its structure and the type of data that it is.

#Anomaly Example
<p align="center">
  <img src="./res/Anomaly.png" width="300px">
</p>

Although it is to be further confirmed, we plan on using 3 techniques. One density-based technique such as; k-nearest neighbor, local outlier factor, isolation forests.
One cluster analysis algorithm, looking for bursts of outlying activity. And finally a Bayesian Networks approach.

The datasets we plan on using are also not locked down. However, we would like to use 3 separate datasets that differ in structure to get the best result. One possibly on card transactions in the realm of fraud detection, one on health-care to point out any faults and one on environmental issues to point out unusual activity although we have not finalised the datasets yet.
The steps that will need to be undertaken are choosing a particular dataset, creating a preliminary report with what we think we will find, cleaning it and applying our algorithms to it in order to obtain results.
Once the algorithms have been developed and applied to the datasets, the next step would be analysis. We will prepare a report of our findings based on the results gathered from running the algorithms over our datasets. Our goal is to be able to say which algorithm worked well with which dataset and why as well as reporting any findings we did not anticipate and explaining our understanding of this.


### Background

The idea for this project first arose when brainstorming ideas for the project together. We both had similar interests in particular areas but liked the idea of doing a data-mining project as it is an area we found to be most interesting and appealing. Although we are interested in this field it is sort of new to us but our interest has driven us to learn more about it and base our project in this area.

While researching project ideas in the area of data mining we came across anomaly detection and realised it is a huge area within data-analytics. It is widely used for fraud detection, fault detection and outlining anything that differs from the norm. We believe anomaly detection to be a very important part of data-mining as it offers just as much information as insights from ‘normal’ data.

We then began looking into what we could do with this, we became aware that there are multiple techniques used for anomaly detection and finding the best one for each data-set can be time consuming and troubling. 

This is when we decided on creating different anomaly detection algorithms based on different techniques. We could then test these techniques on multiple data-sets to possibly find the ‘right’ technique. This is how this research based project idea came about.


### Achievements

The main function of this project is to gain an insight into the different anomaly detection techniques and what algorithms are useful for which type of datasets. We believe that conducting these experiments can outline which algorithm is best suited to which particular dataset based on its structure and other factors and why but also why one algorithm may fail drastically when applied to a particular dataset.

We will provide a report once our research is complete. This report will specify our findings for each technique and each data-set including our own conclusions based on these findings.


### Justification

Anomaly detection is used to find outliers in datasets. It finds rare items, observations or events that raise suspicion and how they differ significantly from the rest of the data. So why is anomaly detection useful? Anomalies in data can often suggest issues such as bank fraud, medical problems, structural defects or even errors in text. As well as using anomaly detection to avoid financial loss it can be applied to many areas regarding healthcare, environmental studies and political research. Insights from data are very useful and important nowadays as we live in a data driven era. The anomalies that can be pointed out are just as useful as normal insights.
Anomaly detection is used in many different areas including:

<p align="center">
  <img src="./res/uses_of_anomaly_detection.png" width="300px">
</p>

<p align="center">
  <img src="./res/FraudDetection.png" width="300px">
</p>

Our plan is to research the different techniques used for anomaly detection and show what techniques should be used for which data sets depending on their structure and data type. Hopefully, anyone hoping to find anomalies in their dataset can learn from our research and choose a technique specific for their dataset based on our findings and results. As well as presenting our results for each dataset we need to understand why a particular algorithm worked well for one but not another and this understanding is what we would like to report alongside our findings.




### Programming language(s)

- Python
- SQL
- HTML
- CSS
- JavaScript
- Markdown

### Programming tools / Tech stack

- Jupyter notebooks
- Pandas
- MySQL


### Learning Challenges

New Tech:

- Jupyter notebook: A open-source web app for creating anf sharing documents. The notebooks will be very useful for equations and visulizations and also for sharing the notebooks between us.
- Statistical modeling: Statistical modeling such as this, is a new concept for us and will be a challenge to learn.
- Database management/MySQL: As we will be using datasets, MySQL will be needed.
- SQL: SQL will bw needed for the above also.

### Breakdown of work

Our strategy at the beginning is to research different techniques separately. As this is a research project and not a development  one our approach may be slightly different in order to separate the work. While we will research techniques separately we will learn from each other regarding different insights the other has obtained.

We will work together to set up the datasets with the MySQL database manager. The management and upkeep of the database will be looked after by both of us.
From there we will split the techniques and individually work on creating an algorithm for all datasets.

As we are doing 3 techniques, the person done first with their original technique will take the last.

From there, we will gather the results and display them for each of the techniques we worked on. We will do a preliminary report on each technique.

The last step will be to gather all results and investigate them, creating a final report based on all techniques and data-sets.

Both of us will work on the docs and commiting to gitlab together.

#### Student 1: Shannon

1. Create method and run with data-sets.
2. Help with third method.
3. Investigate findings for each method/data-set.
4. Prepare report.


#### Student 2: Sian

1. Create method and run with data-sets.
2. Help with third method.
3. Investigate findings for each method/data-set.
4. Prepare report.




